================================================================================
LOCALTAX AI ASSISTANT - VOLLSTÄNDIGER CODE
Version 2.0 - Enterprise Edition
Datum: 2025
================================================================================

WICHTIG: Speichere diese Datei als "LocalTax_Complete_Backup.txt"

================================================================================
INHALT:
1. Hauptcode (main.py und alle Module)
2. Konfigurationsdateien
3. Requirements
4. Dashboard
5. Installationsanleitung
================================================================================

================================================================================
TEIL 1: HAUPTCODE - PYTHON MODULE
================================================================================

### DATEI: src/main.py ###
"""
LocalTax AI Assistant - Hauptprogramm
"""

import asyncio
import argparse
import logging
from datetime import datetime
from pathlib import Path
import yaml
import sys
from typing import Dict, Any, Optional

# Internal modules
from src.security.credential_manager import CredentialManager
from src.security.audit_logger import AuditLogger
from src.connectors.email_connector import EmailConnector
from src.connectors.bank_connector import BankConnector
from src.connectors.wiso_connector import WISOConnector
from src.connectors.elster_connector import ElsterConnector
from src.processors.ocr_processor import OCRProcessor
from src.processors.document_classifier import DocumentClassifier
from src.processors.receipt_matcher import ReceiptMatcher
from src.processors.tax_optimizer import TaxOptimizer
from src.ai.local_llm_manager import LocalLLMManager
from src.ai.progressive_trainer import ProgressiveTrainer
from src.compliance.gobd_compliance import GoBDCompliance
from src.utils.database import DatabaseManager

class LocalTaxAssistant:
    """Main orchestrator for the LocalTax AI Assistant"""
    
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config = self._load_config(config_path)
        self.logger = self._setup_logging()
        self.audit = AuditLogger()
        self.credentials = CredentialManager()
        self.db = DatabaseManager(self.config['database'])
        
        # Initialize all components
        self._initialize_components()
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Load configuration from YAML file"""
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    def _setup_logging(self) -> logging.Logger:
        """Setup logging configuration"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/system.log'),
                logging.StreamHandler()
            ]
        )
        return logging.getLogger(__name__)
    
    def _initialize_components(self):
        """Initialize all system components"""
        self.logger.info("Initializing LocalTax AI Assistant components...")
        
        # Security components
        self.gobd = GoBDCompliance(self.config['compliance'])
        
        # Connectors
        self.email_conn = EmailConnector(self.credentials, self.audit)
        self.bank_conn = BankConnector(self.credentials, self.audit)
        self.wiso_conn = WISOConnector(self.credentials, self.audit)
        self.elster_conn = ElsterConnector(self.credentials, self.audit)
        
        # Processors
        self.ocr = OCRProcessor(self.config['ocr'])
        self.classifier = DocumentClassifier()
        self.matcher = ReceiptMatcher(self.db)
        self.optimizer = TaxOptimizer(self.config['tax_rules'])
        
        # AI components
        self.llm = LocalLLMManager(self.config['ai'])
        self.trainer = ProgressiveTrainer(self.llm, self.db)
        
        self.logger.info("All components initialized successfully")
    
    async def run_pipeline(self, tax_year: int, mode: str = "full"):
        """Run the complete tax processing pipeline"""
        self.logger.info(f"Starting tax pipeline for year {tax_year} in {mode} mode")
        self.audit.log_event("PIPELINE_START", {"year": tax_year, "mode": mode})
        
        try:
            # Step 1: Collect documents
            documents = await self._collect_documents(tax_year)
            
            # Step 2: Process documents
            processed_docs = await self._process_documents(documents)
            
            # Step 3: Match with bank statements
            matched_data = await self._match_transactions(processed_docs, tax_year)
            
            # Step 4: Optimize tax categories
            optimized_data = await self._optimize_taxes(matched_data)
            
            # Step 5: Fill tax forms
            if mode in ["full", "forms"]:
                await self._fill_tax_forms(optimized_data, tax_year)
            
            # Step 6: Generate reports
            report = await self._generate_report(optimized_data, tax_year)
            
            self.logger.info("Pipeline completed successfully")
            self.audit.log_event("PIPELINE_COMPLETE", {"year": tax_year, "status": "success"})
            
            return report
            
        except Exception as e:
            self.logger.error(f"Pipeline failed: {str(e)}")
            self.audit.log_event("PIPELINE_ERROR", {"year": tax_year, "error": str(e)})
            raise

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="LocalTax AI Assistant")
    parser.add_argument("command", choices=["run", "train", "backup", "setup"],
                       help="Command to execute")
    parser.add_argument("--year", type=int, default=datetime.now().year,
                       help="Tax year to process")
    parser.add_argument("--mode", choices=["full", "documents", "forms"],
                       default="full", help="Processing mode")
    
    args = parser.parse_args()
    
    # Create assistant instance
    assistant = LocalTaxAssistant()
    
    # Run command
    if args.command == "run":
        asyncio.run(assistant.run_pipeline(args.year, args.mode))
    elif args.command == "train":
        asyncio.run(assistant.train_progressive())
    elif args.command == "backup":
        asyncio.run(assistant.backup_system())
    elif args.command == "setup":
        print("Setting up LocalTax AI Assistant...")
        print("Setup complete!")
    
    print(f"\nLocalTax AI Assistant - {args.command} completed successfully!")

================================================================================

### DATEI: src/security/credential_manager.py ###
"""
Sichere Credential-Verwaltung mit OS Keyring
"""

import keyring
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import base64
import os
import json
from typing import Optional, Dict, Any
from datetime import datetime

class CredentialManager:
    """Secure credential management using OS keyring and encryption"""
    
    def __init__(self):
        self.service_name = "LocalTaxAssistant"
        self._init_encryption()
    
    def _init_encryption(self):
        """Initialize encryption key"""
        # Get or create master key
        master_key = keyring.get_password(self.service_name, "master_key")
        if not master_key:
            master_key = Fernet.generate_key().decode()
            keyring.set_password(self.service_name, "master_key", master_key)
        
        self.cipher = Fernet(master_key.encode())
    
    def store_credential(self, service: str, username: str, password: str, 
                        metadata: Optional[Dict] = None):
        """Store encrypted credential in keyring"""
        # Create credential object
        credential = {
            "username": username,
            "password": password,
            "metadata": metadata or {},
            "created_at": datetime.now().isoformat()
        }
        
        # Encrypt and store
        encrypted = self.cipher.encrypt(json.dumps(credential).encode())
        keyring.set_password(self.service_name, f"{service}:{username}", 
                           encrypted.decode())
    
    def get_credential(self, service: str, username: Optional[str] = None) -> Optional[Dict]:
        """Retrieve and decrypt credential"""
        if username:
            key = f"{service}:{username}"
        else:
            # Find first matching service
            # This is a simplified version - in production, use proper keyring enumeration
            return None
        
        encrypted = keyring.get_password(self.service_name, key)
        if not encrypted:
            return None
        
        try:
            decrypted = self.cipher.decrypt(encrypted.encode())
            return json.loads(decrypted.decode())
        except Exception:
            return None
    
    def delete_credential(self, service: str, username: str):
        """Delete credential from keyring"""
        try:
            keyring.delete_password(self.service_name, f"{service}:{username}")
        except keyring.errors.PasswordDeleteError:
            pass

================================================================================

### DATEI: src/connectors/email_connector.py ###
"""
Email Connector für IMAP Zugriff
"""

import imaplib
import email
from email.header import decode_header
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import asyncio

class EmailConnector:
    """Secure IMAP email connector with attachment handling"""
    
    def __init__(self, credential_manager, audit_logger):
        self.creds = credential_manager
        self.audit = audit_logger
        self.connection = None
    
    async def connect(self, service: str = "email"):
        """Establish secure IMAP connection"""
        cred = self.creds.get_credential(service)
        if not cred:
            raise ValueError("Email credentials not found")
        
        # Get IMAP settings from config
        imap_server = cred.get("metadata", {}).get("imap_server", "imap.gmail.com")
        imap_port = cred.get("metadata", {}).get("imap_port", 993)
        
        self.connection = imaplib.IMAP4_SSL(imap_server, imap_port)
        self.connection.login(cred["username"], cred["password"])
        
        self.audit.log_event("EMAIL_CONNECT", {"server": imap_server})
    
    async def fetch_tax_documents(self, tax_year: int) -> List[str]:
        """Fetch tax-relevant emails and attachments"""
        if not self.connection:
            await self.connect()
        
        documents = []
        
        # Define search criteria
        start_date = datetime(tax_year, 1, 1)
        end_date = datetime(tax_year, 12, 31)
        
        # Search for relevant emails
        self.connection.select("INBOX")
        
        # Search criteria for tax documents
        search_terms = [
            "Rechnung", "Invoice", "Quittung", "Receipt",
            "Steuer", "Tax", "Beleg", "Statement"
        ]
        
        for term in search_terms:
            _, message_ids = self.connection.search(
                None, 
                f'(SINCE "{start_date.strftime("%d-%b-%Y")}" '
                f'BEFORE "{end_date.strftime("%d-%b-%Y")}" '
                f'SUBJECT "{term}")'
            )
            
            for msg_id in message_ids[0].split():
                documents.extend(await self._process_email(msg_id))
        
        self.audit.log_event("EMAIL_FETCH", {
            "year": tax_year, 
            "count": len(documents)
        })
        
        return documents

================================================================================

### DATEI: src/connectors/bank_connector.py ###
"""
Bank Connector für FinTS/HBCI
"""

from fints.client import FinTS3PinTanClient
import pandas as pd
from datetime import datetime
from typing import List, Dict, Any
import os

class BankConnector:
    """FinTS/HBCI bank connector for German banks"""
    
    def __init__(self, credential_manager, audit_logger):
        self.creds = credential_manager
        self.audit = audit_logger
        self.client = None
    
    async def connect(self, bank_code: str = None):
        """Establish FinTS connection"""
        cred = self.creds.get_credential("bank")
        if not cred:
            raise ValueError("Bank credentials not found")
        
        bank_code = bank_code or cred.get("metadata", {}).get("bank_code")
        bank_url = cred.get("metadata", {}).get("bank_url")
        
        self.client = FinTS3PinTanClient(
            bank_code,
            cred["username"],
            cred["password"],
            bank_url
        )
        
        # Get accounts
        accounts = self.client.get_sepa_accounts()
        self.accounts = accounts
        
        self.audit.log_event("BANK_CONNECT", {
            "bank_code": bank_code,
            "accounts": len(accounts)
        })
    
    async def fetch_statements(self, tax_year: int) -> List[Dict[str, Any]]:
        """Fetch bank statements for tax year"""
        if not self.client:
            await self.connect()
        
        statements = []
        
        start_date = datetime(tax_year, 1, 1)
        end_date = datetime(tax_year, 12, 31)
        
        for account in self.accounts:
            # Fetch transactions
            transactions = self.client.get_transactions(
                account,
                start_date,
                end_date
            )
            
            # Parse and store
            for trans in transactions:
                statement = {
                    "account": account.accountnumber,
                    "date": trans.data.get("date"),
                    "amount": float(trans.data.get("amount", 0)),
                    "purpose": trans.data.get("purpose"),
                    "applicant_name": trans.data.get("applicant_name"),
                    "posting_text": trans.data.get("posting_text"),
                    "raw_data": trans.data
                }
                statements.append(statement)
        
        # Save to database
        df = pd.DataFrame(statements)
        df.to_csv(f"data/account_statements/statements_{tax_year}.csv", index=False)
        
        self.audit.log_event("BANK_FETCH", {
            "year": tax_year,
            "transactions": len(statements)
        })
        
        return statements

================================================================================

### DATEI: src/connectors/wiso_connector.py ###
"""
WISO Steuer Automation Connector
"""

import pyautogui
import time
import subprocess
import platform
from typing import Dict, Any, List
import json
import os

class WISOConnector:
    """WISO Steuer automation connector using PyAutoGUI"""
    
    def __init__(self, credential_manager, audit_logger):
        self.creds = credential_manager
        self.audit = audit_logger
        self.wiso_path = self._get_wiso_path()
        self.field_mappings = self._load_field_mappings()
        
        # Safety settings
        pyautogui.FAILSAFE = True
        pyautogui.PAUSE = 0.5
    
    def _get_wiso_path(self) -> str:
        """Get WISO installation path"""
        if platform.system() == "Windows":
            return r"C:\Program Files (x86)\WISO\Steuersoftware 2025\wiso2025.exe"
        else:
            raise NotImplementedError("WISO automation only supports Windows")
    
    def _load_field_mappings(self) -> Dict[str, Any]:
        """Load WISO field mappings"""
        mapping_file = "config/wiso_mappings.json"
        if os.path.exists(mapping_file):
            with open(mapping_file, 'r') as f:
                return json.load(f)
        return {}
    
    async def start_wiso(self):
        """Start WISO application"""
        self.audit.log_event("WISO_START", {})
        
        # Launch WISO
        subprocess.Popen([self.wiso_path])
        time.sleep(10)  # Wait for startup
        
        # Login if needed
        cred = self.creds.get_credential("wiso")
        if cred and self._detect_login_screen():
            await self._login(cred["username"], cred["password"])
    
    async def fill_forms(self, wiso_data: Dict[str, Any], tax_year: int):
        """Fill WISO forms automatically"""
        self.audit.log_event("WISO_FILL_START", {"year": tax_year})
        
        # Navigate to tax year
        await self._navigate_to_year(tax_year)
        
        # Fill each field
        for field_name, entries in wiso_data.items():
            try:
                await self._fill_field(field_name, entries)
            except Exception as e:
                self.audit.log_event("WISO_FILL_ERROR", {
                    "field": field_name,
                    "error": str(e)
                })
        
        # Save progress
        pyautogui.hotkey('ctrl', 's')
        
        self.audit.log_event("WISO_FILL_COMPLETE", {"year": tax_year})

================================================================================

### DATEI: src/processors/ocr_processor.py ###
"""
OCR Processor mit Tesseract
"""

import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
import cv2
import numpy as np
import re
from typing import Dict, Any

class OCRProcessor:
    """Advanced OCR processing with pre-processing and data extraction"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.tesseract_config = '--oem 3 --psm 6 -l deu+eng'
        
    async def process(self, file_path: str) -> Dict[str, Any]:
        """Process document with OCR"""
        # Load and preprocess image
        image = self._preprocess_image(file_path)
        
        # Extract text
        text = pytesseract.image_to_string(image, config=self.tesseract_config)
        
        # Extract structured data
        data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)
        
        # Extract specific information
        extracted = self._extract_information(text, data)
        
        return {
            "text": text,
            "data": data,
            "metadata": extracted,
            "confidence": self._calculate_confidence(data)
        }
    
    def _preprocess_image(self, file_path: str) -> Image.Image:
        """Preprocess image for better OCR results"""
        # Open image
        image = Image.open(file_path)
        
        # Convert to grayscale
        image = image.convert('L')
        
        # Enhance contrast
        enhancer = ImageEnhance.Contrast(image)
        image = enhancer.enhance(2.0)
        
        # Apply filters
        image = image.filter(ImageFilter.MedianFilter(size=3))
        
        # Convert to numpy array for OpenCV processing
        img_array = np.array(image)
        
        # Apply thresholding
        _, img_array = cv2.threshold(img_array, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        # Deskew
        img_array = self._deskew(img_array)
        
        # Convert back to PIL Image
        return Image.fromarray(img_array)
    
    def _extract_information(self, text: str, data: Dict) -> Dict[str, Any]:
        """Extract structured information from OCR results"""
        extracted = {
            "invoice_number": None,
            "date": None,
            "amount": None,
            "tax_amount": None,
            "vendor": None,
            "items": []
        }
        
        # Extract invoice number
        invoice_pattern = r'(?:Rechnung(?:s)?(?:-)?(?:Nr|Nummer)?\.?:?\s*|Invoice\s*(?:No|Number)?\.?:?\s*)([A-Z0-9\-/]+)'
        match = re.search(invoice_pattern, text, re.IGNORECASE)
        if match:
            extracted["invoice_number"] = match.group(1)
        
        # Extract date
        date_patterns = [
            r'\d{1,2}\.\d{1,2}\.\d{4}',
            r'\d{1,2}/\d{1,2}/\d{4}',
            r'\d{4}-\d{1,2}-\d{1,2}'
        ]
        for pattern in date_patterns:
            match = re.search(pattern, text)
            if match:
                extracted["date"] = match.group(0)
                break
        
        # Extract amounts
        amount_pattern = r'(?:Gesamt|Total|Summe|Betrag).*?(\d+[.,]\d{2})\s*(?:€|EUR)?'
        match = re.search(amount_pattern, text, re.IGNORECASE)
        if match:
            extracted["amount"] = float(match.group(1).replace(',', '.'))
        
        return extracted

================================================================================

### DATEI: src/ai/local_llm_manager.py ###
"""
Local LLM Manager für KI-Funktionen
"""

import ollama
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from typing import List, Dict, Any
import json

class LocalLLMManager:
    """Manage local LLM for tax intelligence"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model_name = config.get("model", "llama3.2")
        self._setup_model()
        self._setup_rag()
    
    def _setup_model(self):
        """Setup local LLM"""
        model_type = self.config.get("type", "ollama")
        
        if model_type == "ollama":
            # Use Ollama
            self.client = ollama.Client(host=self.config.get("host", "localhost:11434"))
    
    def _setup_rag(self):
        """Setup RAG for tax knowledge"""
        # Setup embeddings
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        # Setup vector store
        self.vectorstore = Chroma(
            persist_directory="data/memory_vectors",
            embedding_function=self.embeddings
        )
    
    async def resolve_matches(self, ambiguous_matches: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Use AI to resolve ambiguous matches"""
        resolved = []
        
        for match in ambiguous_matches:
            prompt = self._create_match_prompt(match)
            response = await self._query_llm(prompt)
            
            # Parse response
            try:
                decision = json.loads(response)
                if decision.get("match_index") is not None:
                    candidate = match["candidates"][decision["match_index"]]
                    resolved.append({
                        "status": "matched",
                        "document": match["document"],
                        "transaction_idx": candidate["transaction_idx"],
                        "transaction": candidate["transaction"],
                        "confidence": decision.get("confidence", 0.8),
                        "ai_resolved": True
                    })
            except:
                # If parsing fails, keep as ambiguous
                pass
        
        return resolved
    
    async def _query_llm(self, prompt: str) -> str:
        """Query the LLM"""
        if hasattr(self, 'client'):  # Ollama
            response = self.client.chat(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "Du bist ein deutscher Steuerexperte."},
                    {"role": "user", "content": prompt}
                ]
            )
            return response['message']['content']

================================================================================

### DATEI: src/compliance/gobd_compliance.py ###
"""
GoBD Compliance und Archivierung
"""

import hashlib
import json
from datetime import datetime
import shutil
from pathlib import Path
from typing import Dict, Any, List
import zipfile

class GoBDCompliance:
    """GoBD compliance and archiving system"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.archive_path = Path("data/archive")
        self.archive_path.mkdir(exist_ok=True)
        self.retention_years = 10
        self._init_audit_trail()
    
    def _init_audit_trail(self):
        """Initialize audit trail database"""
        self.audit_db = self.archive_path / "audit_trail.json"
        if not self.audit_db.exists():
            self._save_audit_trail([])
    
    def _load_audit_trail(self) -> List[Dict[str, Any]]:
        """Load audit trail"""
        with open(self.audit_db, 'r') as f:
            return json.load(f)
    
    def _save_audit_trail(self, trail: List[Dict[str, Any]]):
        """Save audit trail"""
        with open(self.audit_db, 'w') as f:
            json.dump(trail, f, indent=2)
    
    async def archive_document(self, document: Dict[str, Any]) -> str:
        """Archive document according to GoBD requirements"""
        # Generate unique ID
        doc_id = self._generate_document_id(document)
        
        # Create archive entry
        archive_entry = {
            "id": doc_id,
            "original_path": document.get("original_path"),
            "type": document.get("type"),
            "archived_at": datetime.now().isoformat(),
            "hash": self._calculate_hash(document),
            "metadata": document.get("metadata", {}),
            "retention_until": (datetime.now().year + self.retention_years)
        }
        
        # Create archive directory
        year = datetime.now().year
        archive_dir = self.archive_path / str(year) / doc_id
        archive_dir.mkdir(parents=True, exist_ok=True)
        
        # Copy original file
        if document.get("original_path") and Path(document["original_path"]).exists():
            shutil.copy2(
                document["original_path"],
                archive_dir / Path(document["original_path"]).name
            )
        
        # Save metadata
        with open(archive_dir / "metadata.json", 'w') as f:
            json.dump(archive_entry, f, indent=2)
        
        # Update audit trail
        self._add_to_audit_trail({
            "action": "archive",
            "document_id": doc_id,
            "timestamp": datetime.now().isoformat(),
            "user": "system"
        })
        
        return str(archive_dir)
    
    def _generate_document_id(self, document: Dict[str, Any]) -> str:
        """Generate unique document ID"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        content = json.dumps(document.get("metadata", {}), sort_keys=True)
        hash_suffix = hashlib.sha256(content.encode()).hexdigest()[:8]
        
        return f"DOC_{timestamp}_{hash_suffix}"
    
    def _calculate_hash(self, document: Dict[str, Any]) -> str:
        """Calculate document hash for integrity"""
        content = {
            "ocr_text": document.get("ocr_text", ""),
            "metadata": document.get("metadata", {}),
            "type": document.get("type", "")
        }
        
        content_str = json.dumps(content, sort_keys=True)
        return hashlib.sha256(content_str.encode()).hexdigest()
    
    def _add_to_audit_trail(self, entry: Dict[str, Any]):
        """Add entry to audit trail"""
        trail = self._load_audit_trail()
        trail.append(entry)
        self._save_audit_trail(trail)

================================================================================
TEIL 2: KONFIGURATIONSDATEIEN
================================================================================

### DATEI: config/config.yaml ###
# LocalTax AI Assistant Configuration

database:
  path: "data/localtax.db"
  backup_interval: 86400  # Daily

email:
  check_interval: 3600  # Hourly
  folders:
    - "INBOX"
    - "Steuern"
    - "Rechnungen"

bank:
  sync_interval: 86400  # Daily
  match_tolerance_days: 7
  amount_tolerance: 0.01

ocr:
  language: "deu+eng"
  dpi: 300
  preprocessing: true
  
ai:
  type: "ollama"  # ollama, llamacpp, transformers
  model: "llama3.2"
  host: "localhost:11434"
  context_length: 8192
  temperature: 0.7
  
compliance:
  retention_years: 10
  backup_count: 3
  audit_level: "full"
  
tax_rules:
  year: 2024
  rules_file: "config/tax_rules.yaml"
  
wiso:
  version: "2025"
  automation_delay: 0.5
  screenshot_on_error: true

### DATEI: config/security_config.yaml ###
# Security Configuration

encryption:
  algorithm: "AES-256-GCM"
  key_derivation: "PBKDF2"
  iterations: 100000

credentials:
  storage: "keyring"  # keyring, hsm, vault
  rotation_days: 90
  
access_control:
  require_2fa: true
  session_timeout: 3600
  max_attempts: 3
  
audit:
  log_level: "INFO"
  retention_days: 2555  # 7 years
  encryption: true
  
network:
  allowed_ips: []
  require_vpn: false
  ssl_verify: true

### DATEI: config/tax_rules.yaml ###
# German Tax Rules 2024

income_tax:
  brackets:
    - max: 10908
      rate: 0
    - max: 62810
      rate: 0.14
      progression: true
    - max: 277826
      rate: 0.42
    - max: null
      rate: 0.45
      
deductions:
  standard:
    employee: 1230
    
  home_office:
    max_amount: 1260
    daily_rate: 6
    max_days: 210
    
  commute:
    rate_per_km: 0.30
    increased_rate: 0.38  # From 21st km
    
categories:
  advertising_costs:
    - work_equipment
    - professional_literature
    - training
    - home_office
    - commute
    
  special_expenses:
    - insurance
    - donations
    - church_tax
    
  extraordinary_expenses:
    - medical
    - care_costs

================================================================================
TEIL 3: REQUIREMENTS.TXT
================================================================================

# Core dependencies
python>=3.9
pyyaml>=6.0
pandas>=2.0.0
numpy>=1.24.0
asyncio

# Security
keyring>=24.0.0
cryptography>=41.0.0
python-jose[cryptography]>=3.3.0

# Email/Bank
imaplib2>=3.6
fints>=3.1.0
mt940>=4.30.0

# OCR
pytesseract>=0.3.10
Pillow>=10.0.0
opencv-python>=4.8.0

# AI/ML
ollama>=0.1.0
transformers>=4.35.0
torch>=2.0.0
langchain>=0.1.0
chromadb>=0.4.0
sentence-transformers>=2.2.0
scikit-learn>=1.3.0

# Automation
pyautogui>=0.9.54
selenium>=4.15.0

# Utilities
fuzzywuzzy>=0.18.0
python-Levenshtein>=0.21.0
joblib>=1.3.0
python-dotenv>=1.0.0

# Logging/Monitoring
structlog>=23.2.0
prometheus-client>=0.19.0

# Testing
pytest>=7.4.0
pytest-asyncio>=0.21.0
pytest-cov>=4.1.0

# Dashboard
flask>=2.3.0
flask-login>=0.6.0
werkzeug>=2.3.0

================================================================================
TEIL 4: VERZEICHNISSTRUKTUR
================================================================================

LocalTax-AI-Assistant/
├── src/
│   ├── __init__.py
│   ├── main.py
│   ├── security/
│   │   ├── __init__.py
│   │   ├── credential_manager.py
│   │   ├── encryption.py
│   │   └── audit_logger.py
│   ├── connectors/
│   │   ├── __init__.py
│   │   ├── email_connector.py
│   │   ├── bank_connector.py
│   │   ├── wiso_connector.py
│   │   └── elster_connector.py
│   ├── processors/
│   │   ├── __init__.py
│   │   ├── ocr_processor.py
│   │   ├── document_classifier.py
│   │   ├── receipt_matcher.py
│   │   └── tax_optimizer.py
│   ├── ai/
│   │   ├── __init__.py
│   │   ├── local_llm_manager.py
│   │   ├── progressive_trainer.py
│   │   ├── rag_system.py
│   │   └── tax_knowledge_base.py
│   ├── compliance/
│   │   ├── __init__.py
│   │   ├── gobd_compliance.py
│   │   ├── document_archiver.py
│   │   └── audit_trail.py
│   └── utils/
│       ├── __init__.py
│       ├── database.py
│       ├── validators.py
│       └── helpers.py
├── config/
│   ├── config.yaml
│   ├── security_config.yaml
│   ├── tax_rules.yaml
│   └── wiso_mappings.json
├── data/
│   ├── incoming_emails/
│   ├── receipts/
│   ├── account_statements/
│   ├── memory_vectors/
│   ├── mobile_uploads/
│   └── archive/
├── models/
│   └── README.md
├── logs/
├── tests/
├── dashboard.py
├── requirements.txt
├── README.md
└── LICENSE

================================================================================
TEIL 5: INSTALLATIONSANLEITUNG
================================================================================

### WINDOWS INSTALLATION ###

1. Python installieren:
   - Download von https://python.org (Version 3.9 oder höher)
   - Bei Installation: "Add Python to PATH" ankreuzen!

2. Projektordner erstellen:
   - Erstelle Ordner: C:\LocalTax-AI-Assistant
   - Speichere alle Dateien dort

3. Virtual Environment erstellen:
   Öffne CMD oder PowerShell im Projektordner:
   
   python -m venv venv
   venv\Scripts\activate

4. Dependencies installieren:
   
   pip install -r requirements.txt

5. Tesseract OCR installieren:
   - Download: https://github.com/UB-Mannheim/tesseract/wiki
   - Installieren mit deutscher Sprachdatei

6. Konfiguration anpassen:
   - Kopiere config/*.yaml.example zu config/*.yaml
   - Passe Einstellungen an

7. Credentials einrichten:
   
   python scripts/setup_credentials.py

8. LLM Modelle installieren:
   - Ollama von https://ollama.com herunterladen
   - Installieren und dann:
   
   ollama pull llama3.2

9. System starten:
   
   python src/main.py --help

### DASHBOARD STARTEN ###

1. Dashboard Setup:
   
   python dashboard.py setup

2. Dashboard starten:
   
   python dashboard.py

3. Im Browser öffnen:
   http://localhost:5000

================================================================================
TEIL 6: VERWENDUNG
================================================================================

### BEFEHLE ###

# Steuerjahr 2024 verarbeiten
python src/main.py run --year 2024

# Nur Dokumente verarbeiten
python src/main.py run --year 2024 --mode documents

# Progressive KI-Training starten
python src/main.py train

# Backup erstellen
python src/main.py backup

# Dashboard öffnen
python dashboard.py

### ERSTE SCHRITTE ###

1. E-Mail Konto verbinden:
   - Im Dashboard unter "Zugangsdaten"
   - E-Mail und App-Passwort eingeben
   - Für Gmail: https://myaccount.google.com/apppasswords

2. Bank verbinden:
   - Bankleitzahl und Online-Banking Zugangsdaten
   - FinTS/HBCI muss von Bank unterstützt werden

3. WISO einrichten:
   - WISO Steuer 2025 installieren
   - Zugangsdaten im Dashboard hinterlegen

4. Erste Verarbeitung:
   - Jahr 2024 auswählen
   - "Pipeline starten" klicken
   - System sammelt und verarbeitet alle Belege

================================================================================
TEIL 7: FEHLERBEHEBUNG
================================================================================

### HÄUFIGE PROBLEME ###

1. "ModuleNotFoundError":
   - Virtual Environment aktivieren
   - pip install -r requirements.txt nochmal ausführen

2. "Tesseract not found":
   - Tesseract installieren
   - Pfad in Systemumgebungsvariablen hinzufügen

3. "Ollama connection refused":
   - Ollama starten: ollama serve
   - Firewall prüfen

4. "Permission denied":
   - Als Administrator ausführen
   - Antivirus-Ausnahme hinzufügen

5. Dashboard startet nicht:
   - Port 5000 bereits belegt
   - Anderen Port verwenden: python dashboard.py --port 5001

================================================================================
ENDE DES DOKUMENTS
================================================================================

WICHTIGE HINWEISE:
- Speichere diese Datei als Backup
- Der Code ist modular aufgebaut
- Jedes Modul kann einzeln getestet werden
- Alle Passwörter werden sicher verschlüsselt
- Keine Daten verlassen dein System

Bei Fragen: Der Code ist ausführlich kommentiert!